{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m img_n \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(subimg, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2HSV)\n\u001b[0;32m     19\u001b[0m img_n \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mGaussianBlur(img_n,(\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m7\u001b[39m),cv2\u001b[38;5;241m.\u001b[39mBORDER_DEFAULT)\n\u001b[1;32m---> 20\u001b[0m hr,wc \u001b[38;5;241m=\u001b[39m img_n\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     21\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting\u001b[39m\u001b[38;5;124m\"\u001b[39m,img_n)\n\u001b[0;32m     22\u001b[0m thres,_,_,_ \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mmean(img_new[\u001b[38;5;241m123\u001b[39m:\u001b[38;5;241m127\u001b[39m,\u001b[38;5;241m98\u001b[39m:\u001b[38;5;241m102\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "i=0\n",
    "key = cv2.waitKey(1)\n",
    "webcam = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    check, frame = webcam.read()\n",
    "#   for i in range(0, 5):\n",
    "    frame = cv2.flip(frame,1)\n",
    "    framecp = frame.copy()\n",
    "    cv2.rectangle(framecp,(390,80),(640,380),(70,0,70), 3)\n",
    "    cv2.circle(framecp, (515,230), 3, (70,0,70), 3)\n",
    "    cv2.imshow(\"Capturing\", framecp)\n",
    "    subimg = frame[80:380,390:640]\n",
    "    img_new = cv2.cvtColor(subimg, cv2.COLOR_BGR2GRAY)\n",
    "    img_n = cv2.cvtColor(subimg, cv2.COLOR_BGR2HSV)\n",
    "    img_n = cv2.GaussianBlur(img_n,(7,7),cv2.BORDER_DEFAULT)\n",
    "    hr,wc = img_n.shape\n",
    "    cv2.imshow(\"Testing\",img_n)\n",
    "    thres,_,_,_ = cv2.mean(img_new[123:127,98:102])\n",
    "    h,w = img_new.shape\n",
    "    rng = 40\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            if img_new[i,j]>thres+rng:\n",
    "                img_new[i,j] = 0\n",
    "            elif img_new[i,j]<thres-rng:\n",
    "                img_new[i,j] = 0\n",
    "            else:\n",
    "                img_new[i,j] = 255\n",
    "    cv2.imshow(\"Sub Image\",img_new)\n",
    "    key = cv2.waitKey(1)\n",
    "         \n",
    "    if key == ord('s'):\n",
    "        cv2.imwrite(filename=str(i)+'_saved_img.jpg', img=subimg)\n",
    "        webcam.release()\n",
    "        img_new = cv2.imread(str(i)+'_saved_img.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "        cv2.imshow(\"Captured Image\", img_new)\n",
    "       # cv2.waitKey(1650)\n",
    "        #cv2.destroyAllWindows()\n",
    "        #print(\"Processing image...\")\n",
    "        #img_new = cv2.imread(str(i)+'_saved_img.jpg', cv2.IMREAD_ANYCOLOR)\n",
    "        #print(\"Converting RGB image to grayscale...\")\n",
    "        #gray = cv2.cvtColor(img_, cv2.COLOR_BGR2GRAY)\n",
    "        #print(\"Converted RGB image to grayscale...\")\n",
    "        #print(\"Converting Gray image to Binary...\")\n",
    "        #retval, dimage = cv2.threshold(img_new, 120, 255, cv2.THRESH_BINARY)\n",
    "        #cv2.imshow(\"Testing\",dimage)\n",
    "        thres,_,_,_ = cv2.mean(img_new[123:127,98:102])\n",
    "        h,w = img_new.shape\n",
    "        rng = 40\n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                if img_new[i,j]>thres+rng:\n",
    "                    img_new[i,j] = 0\n",
    "                elif img_new[i,j]<thres-rng:\n",
    "                    img_new[i,j] = 0\n",
    "                else:\n",
    "                    img_new[i,j] = 255\n",
    "            \n",
    "        cv2.imshow(\"Thresholded\",img_new)\n",
    "        kernel = np.ones((2,2), np.uint8)\n",
    "        img_erode = cv2.erode(img_new, kernel, iterations = 3)\n",
    "        img_dilate = cv2.dilate(img_erode, kernel, iterations = 3)\n",
    "        cv2.imshow(\"dilated\",img_dilate)\n",
    "        #print(\"Converted Gray image to Binary...\")\n",
    "        #print(\"Resizing image to 28x28 scale...\")\n",
    "        img_ = cv2.resize(img_new, (224, 224))\n",
    "        #print(\"Resized...\")\n",
    "        img_resized = cv2.imwrite(filename=str(i)+'_saved_img-final.jpg', img=img_)\n",
    "        cv2.imwrite(filename=str(i)+'_saved_img-dialated.jpg', img=img_dilate)\n",
    "        #print(\"Image saved!\")\n",
    "        i = i+1\n",
    "        webcam = cv2.VideoCapture(0)\n",
    "\n",
    "    elif key == ord('q'):\n",
    "        print(\"Turning off camera.\")\n",
    "        webcam.release()\n",
    "        print(\"Camera off.\")\n",
    "        print(\"Program ended.\")\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image, ImageOps\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m image\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_model\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PIL'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "i=0\n",
    "key = cv2.waitKey(1)\n",
    "webcam = cv2.VideoCapture(0)\n",
    "saved_path = \"VGG_cross_validated.h5\"\n",
    "model = load_model(saved_path)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "while True:\n",
    "\n",
    "    check, frame = webcam.read()\n",
    "    frame = cv2.flip(frame,1)\n",
    "    framecp = frame.copy()\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    cv2.rectangle(framecp,(390,80),(640,380),(70,0,70), 3)\n",
    "   # cv2.circle(framecp, (515,230), 3, (70,0,70), 3)\n",
    "    subimg = frame[80:380,390:640]\n",
    "    hsv = cv2.cvtColor(subimg, cv2.COLOR_BGR2HSV)\n",
    "    lower_skin = np.array([0,20,70], dtype=np.uint8)\n",
    "    upper_skin = np.array([20,255,255], dtype=np.uint8)\n",
    "    mask = cv2.inRange(hsv, lower_skin, upper_skin)\n",
    "    mask = cv2.dilate(mask,kernel,iterations = 4)\n",
    "    mask = cv2.GaussianBlur(mask,(5,5),100)\n",
    "    gs = mask\n",
    "    mask = cv2.threshold(mask, 0, 255, cv2.THRESH_OTSU|cv2.THRESH_BINARY)[1]\n",
    "    thrs = mask\n",
    "    mask = cv2.erode(mask,kernel,iterations = 3)\n",
    "    er=mask\n",
    "    mask = cv2.dilate(mask,kernel,iterations = 3)\n",
    "    dil=mask\n",
    "    imgs = Image.fromarray(mask)\n",
    "    imgs = imgs.convert('RGB')\n",
    "    imgs = ImageOps.fit(imgs, (224,224), Image.ANTIALIAS)\n",
    "    imgs = np.expand_dims(imgs,axis=0)\n",
    "    val = model.predict(imgs)\n",
    "    res = np.where(val == np.amax(val))\n",
    "    \n",
    "    if res[1] == [0]:\n",
    "        cv2.putText(framecp,\"Fist\",(0,50), font, 2, (0,0,255), 3, cv2.LINE_AA)\n",
    "    elif res[1] == [1]:\n",
    "        cv2.putText(framecp,\"L\",(0,50), font, 2, (0,0,255), 3, cv2.LINE_AA)\n",
    "    elif res[1] == [2]:\n",
    "        cv2.putText(framecp,\"OK\",(0,50), font, 2, (0,0,255), 3, cv2.LINE_AA)\n",
    "    elif res[1] == [3]:\n",
    "        cv2.putText(framecp,\"Palm\",(0,50), font, 2, (0,0,255), 3, cv2.LINE_AA)\n",
    "    elif res[1] == [4]:\n",
    "        cv2.putText(framecp,\"Peace\",(0,50), font, 2, (0,0,255), 3, cv2.LINE_AA)\n",
    "    cv2.imshow(\"Testing\",mask)\n",
    "    cv2.imshow(\"Capturing\", framecp)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('s'):\n",
    "        cv2.imwrite(filename=str(i)+'_framecp_img.jpg', img=framecp)\n",
    "        cv2.imwrite(filename=str(i)+'_main_img.jpg', img=subimg)\n",
    "       # cv2.imwrite(filename=str(i)+'_hsv_img.jpg', img=hsv)\n",
    "        #cv2.imwrite(filename=str(i)+'_gauss_img.jpg', img=gs)\n",
    "        #cv2.imwrite(filename=str(i)+'_thrs_img.jpg', img=thrs)\n",
    "        #cv2.imwrite(filename=str(i)+'_er_img.jpg', img=er)\n",
    "        cv2.imwrite(filename=str(i)+'_dil_img.jpg', img=dil)\n",
    "        i=i+1\n",
    "    if key == ord('q'):\n",
    "        print(\"Turning off camera.\")\n",
    "        webcam.release()\n",
    "        print(\"Camera off.\")\n",
    "        print(\"Program ended.\")\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 128)               3211392   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 17,967,685\n",
      "Trainable params: 3,252,997\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5c41a7d16bde>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "tf.math.confusion_matrix()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Confusion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-439aae9c3fdb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConfusion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Confusion' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.math.confusion_matrix(Confusion, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image, ImageOps\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "i=0\n",
    "key = cv2.waitKey(1)\n",
    "webcam = cv2.VideoCapture(0)\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(52, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer = tf.train.AdamOptimizer(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.load_weights(\"model.h5\")\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "while True:\n",
    "\n",
    "    check, frame = webcam.read()\n",
    "    frame = cv2.flip(frame,1)\n",
    "    framecp = frame.copy()\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    cv2.rectangle(framecp,(390,80),(640,380),(70,0,70), 3)\n",
    "    cv2.circle(framecp, (515,230), 3, (70,0,70), 3)\n",
    "    subimg = frame[80:380,390:640]\n",
    "    imgs = Image.fromarray(subimg)\n",
    "    imgs = imgs.convert('RGB')\n",
    "    imgs = ImageOps.fit(imgs, (150,150), Image.ANTIALIAS)\n",
    "    cv2.imshow(\"Given\",np.array(imgs))\n",
    "    imgs = np.expand_dims(imgs,axis=0)\n",
    "    val = model.predict(imgs)\n",
    "    res = np.where(val == np.amax(val))\n",
    "    cv2.putText(framecp,str(res[1]),(0,50), font, 2, (0,0,255), 3, cv2.LINE_AA)\n",
    "    cv2.imshow(\"Capturing\", framecp)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        print(\"Turning off camera.\")\n",
    "        webcam.release()\n",
    "        print(\"Camera off.\")\n",
    "        print(\"Program ended.\")\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
